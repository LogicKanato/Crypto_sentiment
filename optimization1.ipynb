{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import data_process as dp\n",
    "import validate as v\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MovingAverage10</th>\n",
       "      <th>EMA10</th>\n",
       "      <th>MovingAverage21</th>\n",
       "      <th>EMA21</th>\n",
       "      <th>MovingAverage50</th>\n",
       "      <th>EMA50</th>\n",
       "      <th>LowerBB</th>\n",
       "      <th>...</th>\n",
       "      <th>RoC12</th>\n",
       "      <th>Momentum14</th>\n",
       "      <th>RoC14</th>\n",
       "      <th>Momentum21</th>\n",
       "      <th>RoC21</th>\n",
       "      <th>AvgSentiment</th>\n",
       "      <th>TweetFreq</th>\n",
       "      <th>signals_7d</th>\n",
       "      <th>signals_14d</th>\n",
       "      <th>signals_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>75.369476</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.280994</td>\n",
       "      <td>0.258329</td>\n",
       "      <td>0.265562</td>\n",
       "      <td>0.253609</td>\n",
       "      <td>0.243577</td>\n",
       "      <td>0.213209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>1.244813</td>\n",
       "      <td>0.244813</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>0.299970</td>\n",
       "      <td>75.937629</td>\n",
       "      <td>0.280862</td>\n",
       "      <td>0.284444</td>\n",
       "      <td>0.262145</td>\n",
       "      <td>0.268690</td>\n",
       "      <td>0.254089</td>\n",
       "      <td>0.245788</td>\n",
       "      <td>0.216271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242441</td>\n",
       "      <td>1.249354</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>1.364408</td>\n",
       "      <td>0.364408</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>64.976230</td>\n",
       "      <td>0.285562</td>\n",
       "      <td>0.286363</td>\n",
       "      <td>0.265354</td>\n",
       "      <td>0.271082</td>\n",
       "      <td>0.254408</td>\n",
       "      <td>0.247718</td>\n",
       "      <td>0.217471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1.104869</td>\n",
       "      <td>0.104869</td>\n",
       "      <td>1.296104</td>\n",
       "      <td>0.296104</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>0.298950</td>\n",
       "      <td>90.013927</td>\n",
       "      <td>0.290467</td>\n",
       "      <td>0.288652</td>\n",
       "      <td>0.267842</td>\n",
       "      <td>0.273616</td>\n",
       "      <td>0.255018</td>\n",
       "      <td>0.249727</td>\n",
       "      <td>0.219984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195943</td>\n",
       "      <td>1.238216</td>\n",
       "      <td>0.238216</td>\n",
       "      <td>1.211845</td>\n",
       "      <td>0.211845</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>0.298916</td>\n",
       "      <td>88.615791</td>\n",
       "      <td>0.293862</td>\n",
       "      <td>0.290518</td>\n",
       "      <td>0.270648</td>\n",
       "      <td>0.275916</td>\n",
       "      <td>0.256496</td>\n",
       "      <td>0.251656</td>\n",
       "      <td>0.221606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205308</td>\n",
       "      <td>1.195665</td>\n",
       "      <td>0.195665</td>\n",
       "      <td>1.245485</td>\n",
       "      <td>0.245485</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>50796.377674</td>\n",
       "      <td>69.602868</td>\n",
       "      <td>49219.216563</td>\n",
       "      <td>49804.785557</td>\n",
       "      <td>48857.489121</td>\n",
       "      <td>50127.943013</td>\n",
       "      <td>54580.594563</td>\n",
       "      <td>52486.513401</td>\n",
       "      <td>45566.701358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040257</td>\n",
       "      <td>1.085733</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>1.005164</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>47673.044045</td>\n",
       "      <td>47.384776</td>\n",
       "      <td>49296.033600</td>\n",
       "      <td>49417.196192</td>\n",
       "      <td>48719.325846</td>\n",
       "      <td>49904.770380</td>\n",
       "      <td>54183.220334</td>\n",
       "      <td>52297.749897</td>\n",
       "      <td>45497.817908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>-0.057369</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>46470.321575</td>\n",
       "      <td>40.567501</td>\n",
       "      <td>49255.423065</td>\n",
       "      <td>48881.400807</td>\n",
       "      <td>48527.405237</td>\n",
       "      <td>49592.547761</td>\n",
       "      <td>53770.715052</td>\n",
       "      <td>52069.223296</td>\n",
       "      <td>45290.272181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.951664</td>\n",
       "      <td>-0.048336</td>\n",
       "      <td>0.920192</td>\n",
       "      <td>-0.079808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>47102.463004</td>\n",
       "      <td>47.657892</td>\n",
       "      <td>49270.193018</td>\n",
       "      <td>48557.957570</td>\n",
       "      <td>48487.626197</td>\n",
       "      <td>49366.176420</td>\n",
       "      <td>53417.642753</td>\n",
       "      <td>51874.448382</td>\n",
       "      <td>45246.062154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.988230</td>\n",
       "      <td>-0.011770</td>\n",
       "      <td>0.982574</td>\n",
       "      <td>-0.017426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>46355.117330</td>\n",
       "      <td>50.090539</td>\n",
       "      <td>48997.498504</td>\n",
       "      <td>48157.441163</td>\n",
       "      <td>48436.097071</td>\n",
       "      <td>49092.443775</td>\n",
       "      <td>53045.486474</td>\n",
       "      <td>51658.004027</td>\n",
       "      <td>44980.823139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011121</td>\n",
       "      <td>1.000445</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.977189</td>\n",
       "      <td>-0.022811</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Price        RSI  MovingAverage10         EMA10  \\\n",
       "167   2011-01-01      0.300000  75.369476         0.275862      0.280994   \n",
       "168   2011-01-02      0.299970  75.937629         0.280862      0.284444   \n",
       "169   2011-01-03      0.295000  64.976230         0.285562      0.286363   \n",
       "170   2011-01-04      0.298950  90.013927         0.290467      0.288652   \n",
       "171   2011-01-05      0.298916  88.615791         0.293862      0.290518   \n",
       "...          ...           ...        ...              ...           ...   \n",
       "4180  2021-12-27  50796.377674  69.602868     49219.216563  49804.785557   \n",
       "4181  2021-12-28  47673.044045  47.384776     49296.033600  49417.196192   \n",
       "4182  2021-12-29  46470.321575  40.567501     49255.423065  48881.400807   \n",
       "4183  2021-12-30  47102.463004  47.657892     49270.193018  48557.957570   \n",
       "4184  2021-12-31  46355.117330  50.090539     48997.498504  48157.441163   \n",
       "\n",
       "      MovingAverage21         EMA21  MovingAverage50         EMA50  \\\n",
       "167          0.258329      0.265562         0.253609      0.243577   \n",
       "168          0.262145      0.268690         0.254089      0.245788   \n",
       "169          0.265354      0.271082         0.254408      0.247718   \n",
       "170          0.267842      0.273616         0.255018      0.249727   \n",
       "171          0.270648      0.275916         0.256496      0.251656   \n",
       "...               ...           ...              ...           ...   \n",
       "4180     48857.489121  50127.943013     54580.594563  52486.513401   \n",
       "4181     48719.325846  49904.770380     54183.220334  52297.749897   \n",
       "4182     48527.405237  49592.547761     53770.715052  52069.223296   \n",
       "4183     48487.626197  49366.176420     53417.642753  51874.448382   \n",
       "4184     48436.097071  49092.443775     53045.486474  51658.004027   \n",
       "\n",
       "           LowerBB  ...     RoC12  Momentum14     RoC14  Momentum21     RoC21  \\\n",
       "167       0.213209  ...  0.123596    1.244813  0.244813    1.315789  0.315789   \n",
       "168       0.216271  ...  0.242441    1.249354  0.249354    1.364408  0.364408   \n",
       "169       0.217471  ...  0.180000    1.104869  0.104869    1.296104  0.296104   \n",
       "170       0.219984  ...  0.195943    1.238216  0.238216    1.211845  0.211845   \n",
       "171       0.221606  ...  0.205308    1.195665  0.195665    1.245485  0.245485   \n",
       "...            ...  ...       ...         ...       ...         ...       ...   \n",
       "4180  45566.701358  ...  0.040257    1.085733  0.085733    1.005164  0.005164   \n",
       "4181  45497.817908  ...  0.000201    0.987169 -0.012831    0.942631 -0.057369   \n",
       "4182  45290.272181  ...  0.002932    0.951664 -0.048336    0.920192 -0.079808   \n",
       "4183  45246.062154  ...  0.004213    0.988230 -0.011770    0.982574 -0.017426   \n",
       "4184  44980.823139  ... -0.011121    1.000445  0.000445    0.977189 -0.022811   \n",
       "\n",
       "      AvgSentiment  TweetFreq  signals_7d  signals_14d  signals_30d  \n",
       "167            1.0   0.000014         1.0          1.0          1.0  \n",
       "168            0.5   0.000000         1.0          1.0          1.0  \n",
       "169            0.5   0.000000         1.0          1.0          1.0  \n",
       "170            0.5   0.000000         1.0          1.0          1.0  \n",
       "171            0.5   0.000000         1.0          1.0          1.0  \n",
       "...            ...        ...         ...          ...          ...  \n",
       "4180           0.5   0.000000         NaN          NaN          NaN  \n",
       "4181           0.5   0.000000         NaN          NaN          NaN  \n",
       "4182           1.0   0.052500         NaN          NaN          NaN  \n",
       "4183           1.0   0.349371         NaN          NaN          NaN  \n",
       "4184           0.5   0.000000         NaN          NaN          NaN  \n",
       "\n",
       "[4018 rows x 26 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FinalDataLabeled.csv',  index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dp.profits(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MovingAverage10</th>\n",
       "      <th>EMA10</th>\n",
       "      <th>MovingAverage21</th>\n",
       "      <th>EMA21</th>\n",
       "      <th>MovingAverage50</th>\n",
       "      <th>EMA50</th>\n",
       "      <th>LowerBB</th>\n",
       "      <th>...</th>\n",
       "      <th>Momentum14</th>\n",
       "      <th>RoC14</th>\n",
       "      <th>Momentum21</th>\n",
       "      <th>RoC21</th>\n",
       "      <th>AvgSentiment</th>\n",
       "      <th>TweetFreq</th>\n",
       "      <th>signals_7d</th>\n",
       "      <th>signals_14d</th>\n",
       "      <th>signals_30d</th>\n",
       "      <th>signals_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>75.369476</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.280994</td>\n",
       "      <td>0.258329</td>\n",
       "      <td>0.265562</td>\n",
       "      <td>0.253609</td>\n",
       "      <td>0.243577</td>\n",
       "      <td>0.213209</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244813</td>\n",
       "      <td>0.244813</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>0.299970</td>\n",
       "      <td>75.937629</td>\n",
       "      <td>0.280862</td>\n",
       "      <td>0.284444</td>\n",
       "      <td>0.262145</td>\n",
       "      <td>0.268690</td>\n",
       "      <td>0.254089</td>\n",
       "      <td>0.245788</td>\n",
       "      <td>0.216271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.249354</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>1.364408</td>\n",
       "      <td>0.364408</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>64.976230</td>\n",
       "      <td>0.285562</td>\n",
       "      <td>0.286363</td>\n",
       "      <td>0.265354</td>\n",
       "      <td>0.271082</td>\n",
       "      <td>0.254408</td>\n",
       "      <td>0.247718</td>\n",
       "      <td>0.217471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.104869</td>\n",
       "      <td>0.104869</td>\n",
       "      <td>1.296104</td>\n",
       "      <td>0.296104</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>0.298950</td>\n",
       "      <td>90.013927</td>\n",
       "      <td>0.290467</td>\n",
       "      <td>0.288652</td>\n",
       "      <td>0.267842</td>\n",
       "      <td>0.273616</td>\n",
       "      <td>0.255018</td>\n",
       "      <td>0.249727</td>\n",
       "      <td>0.219984</td>\n",
       "      <td>...</td>\n",
       "      <td>1.238216</td>\n",
       "      <td>0.238216</td>\n",
       "      <td>1.211845</td>\n",
       "      <td>0.211845</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>0.298916</td>\n",
       "      <td>88.615791</td>\n",
       "      <td>0.293862</td>\n",
       "      <td>0.290518</td>\n",
       "      <td>0.270648</td>\n",
       "      <td>0.275916</td>\n",
       "      <td>0.256496</td>\n",
       "      <td>0.251656</td>\n",
       "      <td>0.221606</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195665</td>\n",
       "      <td>0.195665</td>\n",
       "      <td>1.245485</td>\n",
       "      <td>0.245485</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>50796.377674</td>\n",
       "      <td>69.602868</td>\n",
       "      <td>49219.216563</td>\n",
       "      <td>49804.785557</td>\n",
       "      <td>48857.489121</td>\n",
       "      <td>50127.943013</td>\n",
       "      <td>54580.594563</td>\n",
       "      <td>52486.513401</td>\n",
       "      <td>45566.701358</td>\n",
       "      <td>...</td>\n",
       "      <td>1.085733</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>1.005164</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>47673.044045</td>\n",
       "      <td>47.384776</td>\n",
       "      <td>49296.033600</td>\n",
       "      <td>49417.196192</td>\n",
       "      <td>48719.325846</td>\n",
       "      <td>49904.770380</td>\n",
       "      <td>54183.220334</td>\n",
       "      <td>52297.749897</td>\n",
       "      <td>45497.817908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>-0.057369</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>46470.321575</td>\n",
       "      <td>40.567501</td>\n",
       "      <td>49255.423065</td>\n",
       "      <td>48881.400807</td>\n",
       "      <td>48527.405237</td>\n",
       "      <td>49592.547761</td>\n",
       "      <td>53770.715052</td>\n",
       "      <td>52069.223296</td>\n",
       "      <td>45290.272181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951664</td>\n",
       "      <td>-0.048336</td>\n",
       "      <td>0.920192</td>\n",
       "      <td>-0.079808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>47102.463004</td>\n",
       "      <td>47.657892</td>\n",
       "      <td>49270.193018</td>\n",
       "      <td>48557.957570</td>\n",
       "      <td>48487.626197</td>\n",
       "      <td>49366.176420</td>\n",
       "      <td>53417.642753</td>\n",
       "      <td>51874.448382</td>\n",
       "      <td>45246.062154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988230</td>\n",
       "      <td>-0.011770</td>\n",
       "      <td>0.982574</td>\n",
       "      <td>-0.017426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>46355.117330</td>\n",
       "      <td>50.090539</td>\n",
       "      <td>48997.498504</td>\n",
       "      <td>48157.441163</td>\n",
       "      <td>48436.097071</td>\n",
       "      <td>49092.443775</td>\n",
       "      <td>53045.486474</td>\n",
       "      <td>51658.004027</td>\n",
       "      <td>44980.823139</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000445</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.977189</td>\n",
       "      <td>-0.022811</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4018 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Price        RSI  MovingAverage10         EMA10  \\\n",
       "167   2011-01-01      0.300000  75.369476         0.275862      0.280994   \n",
       "168   2011-01-02      0.299970  75.937629         0.280862      0.284444   \n",
       "169   2011-01-03      0.295000  64.976230         0.285562      0.286363   \n",
       "170   2011-01-04      0.298950  90.013927         0.290467      0.288652   \n",
       "171   2011-01-05      0.298916  88.615791         0.293862      0.290518   \n",
       "...          ...           ...        ...              ...           ...   \n",
       "4180  2021-12-27  50796.377674  69.602868     49219.216563  49804.785557   \n",
       "4181  2021-12-28  47673.044045  47.384776     49296.033600  49417.196192   \n",
       "4182  2021-12-29  46470.321575  40.567501     49255.423065  48881.400807   \n",
       "4183  2021-12-30  47102.463004  47.657892     49270.193018  48557.957570   \n",
       "4184  2021-12-31  46355.117330  50.090539     48997.498504  48157.441163   \n",
       "\n",
       "      MovingAverage21         EMA21  MovingAverage50         EMA50  \\\n",
       "167          0.258329      0.265562         0.253609      0.243577   \n",
       "168          0.262145      0.268690         0.254089      0.245788   \n",
       "169          0.265354      0.271082         0.254408      0.247718   \n",
       "170          0.267842      0.273616         0.255018      0.249727   \n",
       "171          0.270648      0.275916         0.256496      0.251656   \n",
       "...               ...           ...              ...           ...   \n",
       "4180     48857.489121  50127.943013     54580.594563  52486.513401   \n",
       "4181     48719.325846  49904.770380     54183.220334  52297.749897   \n",
       "4182     48527.405237  49592.547761     53770.715052  52069.223296   \n",
       "4183     48487.626197  49366.176420     53417.642753  51874.448382   \n",
       "4184     48436.097071  49092.443775     53045.486474  51658.004027   \n",
       "\n",
       "           LowerBB  ...  Momentum14     RoC14  Momentum21     RoC21  \\\n",
       "167       0.213209  ...    1.244813  0.244813    1.315789  0.315789   \n",
       "168       0.216271  ...    1.249354  0.249354    1.364408  0.364408   \n",
       "169       0.217471  ...    1.104869  0.104869    1.296104  0.296104   \n",
       "170       0.219984  ...    1.238216  0.238216    1.211845  0.211845   \n",
       "171       0.221606  ...    1.195665  0.195665    1.245485  0.245485   \n",
       "...            ...  ...         ...       ...         ...       ...   \n",
       "4180  45566.701358  ...    1.085733  0.085733    1.005164  0.005164   \n",
       "4181  45497.817908  ...    0.987169 -0.012831    0.942631 -0.057369   \n",
       "4182  45290.272181  ...    0.951664 -0.048336    0.920192 -0.079808   \n",
       "4183  45246.062154  ...    0.988230 -0.011770    0.982574 -0.017426   \n",
       "4184  44980.823139  ...    1.000445  0.000445    0.977189 -0.022811   \n",
       "\n",
       "      AvgSentiment  TweetFreq  signals_7d  signals_14d  signals_30d  \\\n",
       "167            1.0   0.000014         1.0          1.0          1.0   \n",
       "168            0.5   0.000000         1.0          1.0          1.0   \n",
       "169            0.5   0.000000         1.0          1.0          1.0   \n",
       "170            0.5   0.000000         1.0          1.0          1.0   \n",
       "171            0.5   0.000000         1.0          1.0          1.0   \n",
       "...            ...        ...         ...          ...          ...   \n",
       "4180           0.5   0.000000         NaN          NaN          NaN   \n",
       "4181           0.5   0.000000         NaN          NaN          NaN   \n",
       "4182           1.0   0.052500         NaN          NaN          NaN   \n",
       "4183           1.0   0.349371         NaN          NaN          NaN   \n",
       "4184           0.5   0.000000         NaN          NaN          NaN   \n",
       "\n",
       "      signals_1d  \n",
       "167          0.0  \n",
       "168          0.0  \n",
       "169          1.0  \n",
       "170          0.0  \n",
       "171          0.0  \n",
       "...          ...  \n",
       "4180         0.0  \n",
       "4181         0.0  \n",
       "4182         1.0  \n",
       "4183         0.0  \n",
       "4184         NaN  \n",
       "\n",
       "[4018 rows x 27 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MovingAverage10</th>\n",
       "      <th>EMA10</th>\n",
       "      <th>MovingAverage21</th>\n",
       "      <th>EMA21</th>\n",
       "      <th>MovingAverage50</th>\n",
       "      <th>EMA50</th>\n",
       "      <th>LowerBB</th>\n",
       "      <th>...</th>\n",
       "      <th>Momentum14</th>\n",
       "      <th>RoC14</th>\n",
       "      <th>Momentum21</th>\n",
       "      <th>RoC21</th>\n",
       "      <th>AvgSentiment</th>\n",
       "      <th>TweetFreq</th>\n",
       "      <th>signals_7d</th>\n",
       "      <th>signals_14d</th>\n",
       "      <th>signals_30d</th>\n",
       "      <th>signals_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>314.776472</td>\n",
       "      <td>50.602414</td>\n",
       "      <td>319.924813</td>\n",
       "      <td>319.468805</td>\n",
       "      <td>327.067766</td>\n",
       "      <td>328.172198</td>\n",
       "      <td>353.887226</td>\n",
       "      <td>345.515290</td>\n",
       "      <td>300.070243</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004034</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.902991</td>\n",
       "      <td>-0.097009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>315.942732</td>\n",
       "      <td>48.865961</td>\n",
       "      <td>317.910673</td>\n",
       "      <td>318.827701</td>\n",
       "      <td>325.294057</td>\n",
       "      <td>327.060428</td>\n",
       "      <td>351.767791</td>\n",
       "      <td>344.355582</td>\n",
       "      <td>300.589318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992772</td>\n",
       "      <td>-0.007228</td>\n",
       "      <td>0.894539</td>\n",
       "      <td>-0.105461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>285.647310</td>\n",
       "      <td>31.474856</td>\n",
       "      <td>314.172175</td>\n",
       "      <td>312.794903</td>\n",
       "      <td>322.265693</td>\n",
       "      <td>323.295599</td>\n",
       "      <td>349.512959</td>\n",
       "      <td>342.053296</td>\n",
       "      <td>296.156665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865425</td>\n",
       "      <td>-0.134575</td>\n",
       "      <td>0.817904</td>\n",
       "      <td>-0.182096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>263.334575</td>\n",
       "      <td>28.344632</td>\n",
       "      <td>308.606018</td>\n",
       "      <td>303.802116</td>\n",
       "      <td>317.849258</td>\n",
       "      <td>317.844597</td>\n",
       "      <td>347.219774</td>\n",
       "      <td>338.966288</td>\n",
       "      <td>283.766133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820376</td>\n",
       "      <td>-0.179624</td>\n",
       "      <td>0.739538</td>\n",
       "      <td>-0.260462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>275.003852</td>\n",
       "      <td>28.782956</td>\n",
       "      <td>303.185369</td>\n",
       "      <td>298.566068</td>\n",
       "      <td>314.416337</td>\n",
       "      <td>313.949984</td>\n",
       "      <td>344.915735</td>\n",
       "      <td>336.457957</td>\n",
       "      <td>276.788537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828718</td>\n",
       "      <td>-0.171282</td>\n",
       "      <td>0.792301</td>\n",
       "      <td>-0.207699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>50796.377674</td>\n",
       "      <td>69.602868</td>\n",
       "      <td>49219.216563</td>\n",
       "      <td>49804.785557</td>\n",
       "      <td>48857.489121</td>\n",
       "      <td>50127.943013</td>\n",
       "      <td>54580.594563</td>\n",
       "      <td>52486.513401</td>\n",
       "      <td>45566.701358</td>\n",
       "      <td>...</td>\n",
       "      <td>1.085733</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>1.005164</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>47673.044045</td>\n",
       "      <td>47.384776</td>\n",
       "      <td>49296.033600</td>\n",
       "      <td>49417.196192</td>\n",
       "      <td>48719.325846</td>\n",
       "      <td>49904.770380</td>\n",
       "      <td>54183.220334</td>\n",
       "      <td>52297.749897</td>\n",
       "      <td>45497.817908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>-0.057369</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>46470.321575</td>\n",
       "      <td>40.567501</td>\n",
       "      <td>49255.423065</td>\n",
       "      <td>48881.400807</td>\n",
       "      <td>48527.405237</td>\n",
       "      <td>49592.547761</td>\n",
       "      <td>53770.715052</td>\n",
       "      <td>52069.223296</td>\n",
       "      <td>45290.272181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951664</td>\n",
       "      <td>-0.048336</td>\n",
       "      <td>0.920192</td>\n",
       "      <td>-0.079808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>47102.463004</td>\n",
       "      <td>47.657892</td>\n",
       "      <td>49270.193018</td>\n",
       "      <td>48557.957570</td>\n",
       "      <td>48487.626197</td>\n",
       "      <td>49366.176420</td>\n",
       "      <td>53417.642753</td>\n",
       "      <td>51874.448382</td>\n",
       "      <td>45246.062154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988230</td>\n",
       "      <td>-0.011770</td>\n",
       "      <td>0.982574</td>\n",
       "      <td>-0.017426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>46355.117330</td>\n",
       "      <td>50.090539</td>\n",
       "      <td>48997.498504</td>\n",
       "      <td>48157.441163</td>\n",
       "      <td>48436.097071</td>\n",
       "      <td>49092.443775</td>\n",
       "      <td>53045.486474</td>\n",
       "      <td>51658.004027</td>\n",
       "      <td>44980.823139</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000445</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.977189</td>\n",
       "      <td>-0.022811</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2557 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Price        RSI  MovingAverage10         EMA10  \\\n",
       "1628 2015-01-01    314.776472  50.602414       319.924813    319.468805   \n",
       "1629 2015-01-02    315.942732  48.865961       317.910673    318.827701   \n",
       "1630 2015-01-03    285.647310  31.474856       314.172175    312.794903   \n",
       "1631 2015-01-04    263.334575  28.344632       308.606018    303.802116   \n",
       "1632 2015-01-05    275.003852  28.782956       303.185369    298.566068   \n",
       "...         ...           ...        ...              ...           ...   \n",
       "4180 2021-12-27  50796.377674  69.602868     49219.216563  49804.785557   \n",
       "4181 2021-12-28  47673.044045  47.384776     49296.033600  49417.196192   \n",
       "4182 2021-12-29  46470.321575  40.567501     49255.423065  48881.400807   \n",
       "4183 2021-12-30  47102.463004  47.657892     49270.193018  48557.957570   \n",
       "4184 2021-12-31  46355.117330  50.090539     48997.498504  48157.441163   \n",
       "\n",
       "      MovingAverage21         EMA21  MovingAverage50         EMA50  \\\n",
       "1628       327.067766    328.172198       353.887226    345.515290   \n",
       "1629       325.294057    327.060428       351.767791    344.355582   \n",
       "1630       322.265693    323.295599       349.512959    342.053296   \n",
       "1631       317.849258    317.844597       347.219774    338.966288   \n",
       "1632       314.416337    313.949984       344.915735    336.457957   \n",
       "...               ...           ...              ...           ...   \n",
       "4180     48857.489121  50127.943013     54580.594563  52486.513401   \n",
       "4181     48719.325846  49904.770380     54183.220334  52297.749897   \n",
       "4182     48527.405237  49592.547761     53770.715052  52069.223296   \n",
       "4183     48487.626197  49366.176420     53417.642753  51874.448382   \n",
       "4184     48436.097071  49092.443775     53045.486474  51658.004027   \n",
       "\n",
       "           LowerBB  ...  Momentum14     RoC14  Momentum21     RoC21  \\\n",
       "1628    300.070243  ...    1.004034  0.004034    0.902991 -0.097009   \n",
       "1629    300.589318  ...    0.992772 -0.007228    0.894539 -0.105461   \n",
       "1630    296.156665  ...    0.865425 -0.134575    0.817904 -0.182096   \n",
       "1631    283.766133  ...    0.820376 -0.179624    0.739538 -0.260462   \n",
       "1632    276.788537  ...    0.828718 -0.171282    0.792301 -0.207699   \n",
       "...            ...  ...         ...       ...         ...       ...   \n",
       "4180  45566.701358  ...    1.085733  0.085733    1.005164  0.005164   \n",
       "4181  45497.817908  ...    0.987169 -0.012831    0.942631 -0.057369   \n",
       "4182  45290.272181  ...    0.951664 -0.048336    0.920192 -0.079808   \n",
       "4183  45246.062154  ...    0.988230 -0.011770    0.982574 -0.017426   \n",
       "4184  44980.823139  ...    1.000445  0.000445    0.977189 -0.022811   \n",
       "\n",
       "      AvgSentiment  TweetFreq  signals_7d  signals_14d  signals_30d  \\\n",
       "1628           1.0   0.008380         0.0          0.0          0.0   \n",
       "1629           1.0   0.007996         0.0          0.0          0.0   \n",
       "1630           1.0   0.007337         0.0          0.0          0.0   \n",
       "1631           1.0   0.009463         1.0          0.0          0.0   \n",
       "1632           1.0   0.007543         0.0          0.0          0.0   \n",
       "...            ...        ...         ...          ...          ...   \n",
       "4180           0.5   0.000000         NaN          NaN          NaN   \n",
       "4181           0.5   0.000000         NaN          NaN          NaN   \n",
       "4182           1.0   0.052500         NaN          NaN          NaN   \n",
       "4183           1.0   0.349371         NaN          NaN          NaN   \n",
       "4184           0.5   0.000000         NaN          NaN          NaN   \n",
       "\n",
       "      signals_1d  \n",
       "1628         1.0  \n",
       "1629         0.0  \n",
       "1630         0.0  \n",
       "1631         1.0  \n",
       "1632         1.0  \n",
       "...          ...  \n",
       "4180         0.0  \n",
       "4181         0.0  \n",
       "4182         1.0  \n",
       "4183         0.0  \n",
       "4184         NaN  \n",
       "\n",
       "[2557 rows x 27 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fil = df\n",
    "df_fil['Date'] = pd.to_datetime(df_fil['Date'],format='%Y-%m-%d')\n",
    "df_fil = df_fil[df_fil['Date'] >= pd.Timestamp(2015, 1, 1)]\n",
    "df_fil = df_fil[df_fil['Date'] <= pd.Timestamp(2021, 12, 31)]\n",
    "df_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = dp.scale_split(df_fil, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                   \n",
      "Generation 1 - Current best internal CV score: 0.809995890893437\n",
      "                                                                                   \n",
      "Generation 2 - Current best internal CV score: 0.809995890893437\n",
      "                                                                                   \n",
      "Generation 3 - Current best internal CV score: 0.8104909403983876\n",
      "                                                                                   \n",
      "Generation 4 - Current best internal CV score: 0.8104909403983876\n",
      "                                                                                   \n",
      "Generation 5 - Current best internal CV score: 0.8104909403983876\n",
      "                                                                                   \n",
      "Generation 6 - Current best internal CV score: 0.8154414354478927\n",
      "                                                                                     \n",
      "Generation 7 - Current best internal CV score: 0.8184029272492466\n",
      "                                                                                     \n",
      "Generation 8 - Current best internal CV score: 0.8184029272492466\n",
      "                                                                                     \n",
      "Generation 9 - Current best internal CV score: 0.8184029272492466\n",
      "                                                                                      \n",
      "Generation 10 - Current best internal CV score: 0.8189048252651352\n",
      "                                                                                      \n",
      "Generation 11 - Current best internal CV score: 0.8189048252651352\n",
      "                                                                                      \n",
      "Generation 12 - Current best internal CV score: 0.8189048252651352\n",
      "                                                                                      \n",
      "Generation 13 - Current best internal CV score: 0.8198910108402144\n",
      "                                                                                      \n",
      "Generation 14 - Current best internal CV score: 0.8198910108402144\n",
      "                                                                                      \n",
      "Generation 15 - Current best internal CV score: 0.8198910108402144\n",
      "                                                                                      \n",
      "Generation 16 - Current best internal CV score: 0.8258364966931475\n",
      "                                                                                      \n",
      "Generation 17 - Current best internal CV score: 0.8258364966931475\n",
      "                                                                                      \n",
      "Generation 18 - Current best internal CV score: 0.8258364966931475\n",
      "                                                                                      \n",
      "Generation 19 - Current best internal CV score: 0.8268265957030485\n",
      "                                                                                      \n",
      "Generation 20 - Current best internal CV score: 0.8268265957030485\n",
      "                                                                                      \n",
      "Generation 21 - Current best internal CV score: 0.8268265957030485\n",
      "                                                                                      \n",
      "Generation 22 - Current best internal CV score: 0.8268265957030485\n",
      "                                                                                      \n",
      "Generation 23 - Current best internal CV score: 0.8268265957030485\n",
      "                                                                                      \n",
      "Generation 24 - Current best internal CV score: 0.8268265957030485\n",
      "                                                                                      \n",
      "The optimized pipeline was not improved after evaluating 5 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "                                                                                      \n",
      "Best pipeline: MLPClassifier(MLPClassifier(MLPClassifier(CombineDFs(CombineDFs(input_matrix, input_matrix), MLPClassifier(input_matrix, activation=identity, alpha=0.01, hidden_layer_sizes=100, learning_rate=constant, max_iter=500, solver=lbfgs)), activation=tanh, alpha=0.0001, hidden_layer_sizes=150, learning_rate=invscaling, max_iter=500, solver=adam), activation=tanh, alpha=0.1, hidden_layer_sizes=250, learning_rate=invscaling, max_iter=500, solver=lbfgs), activation=relu, alpha=1e-05, hidden_layer_sizes=250, learning_rate=adaptive, max_iter=500, solver=sgd)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.neural_network.MLPClassifier': {'activation': ['identity',\n",
       "                                                                                    'logistic',\n",
       "                                                                                    'tanh',\n",
       "                                                                                    'relu'],\n",
       "                                                                     'alpha': [0.1,\n",
       "                                                                               0.01,\n",
       "                                                                               0.001,\n",
       "                                                                               0.0001,\n",
       "                                                                               1e-05],\n",
       "                                                                     'hidden_layer_sizes': [10,\n",
       "                                                                                            20,\n",
       "                                                                                            50,\n",
       "                                                                                            100,\n",
       "                                                                                            150,\n",
       "                                                                                            200,\n",
       "                                                                                            250],\n",
       "                                                                     'learning_rate': ['constant',\n",
       "                                                                                       'invscaling',\n",
       "                                                                                       'adaptive'],\n",
       "                                                                     'max_iter': [500],\n",
       "                                                                     'solver': ['lbfgs',\n",
       "                                                                                'sgd',\n",
       "                                                                                'adam']}},\n",
       "               cv=4, early_stop=5, n_jobs=-1, scoring='accuracy', verbosity=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "parameters = {'hidden_layer_sizes' : [10,20,50,100,150,200,250],\n",
    "              'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate': ['constant','invscaling','adaptive'],\n",
    "              'alpha': [0.1,0.01,0.001,0.0001,0.00001],\n",
    "              'max_iter': [500]}\n",
    "               \n",
    "tpot_classifier = TPOTClassifier(verbosity= 2, early_stop=5, n_jobs = -1,\n",
    "                                 config_dict=\n",
    "                                 {'sklearn.neural_network.MLPClassifier': parameters}, \n",
    "                                 cv = 4, scoring = 'accuracy')\n",
    "\n",
    "tpot_classifier.fit(x_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.782608695652174"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_classifier.score(x_test, y_test) # 30days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = dp.scale_split(df_fil, 7, 1)\n",
    "# x_test.drop(['signals_0d'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6686274509803921"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_classifier.score(x_test, y_test) # 7days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = dp.scale_split(df_fil, 14, 1)\n",
    "# x_test.drop(['signals_0d'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 23 features, but MLPClassifier is expecting 22 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kanat\\OneDrive\\Desktop\\CSC\\474\\Project\\NN3.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kanat/OneDrive/Desktop/CSC/474/Project/NN3.ipynb#ch0000009?line=0'>1</a>\u001b[0m tpot_classifier\u001b[39m.\u001b[39;49mscore(x_test, y_test)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tpot\\base.py:1104\u001b[0m, in \u001b[0;36mTPOTBase.score\u001b[1;34m(self, testing_features, testing_target)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1099'>1100</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1100'>1101</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1101'>1102</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe scoring function should either be the name of a scikit-learn scorer or a scorer object\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1102'>1103</a>\u001b[0m     )\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1103'>1104</a>\u001b[0m score \u001b[39m=\u001b[39m scorer(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1104'>1105</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitted_pipeline_,\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1105'>1106</a>\u001b[0m     testing_features\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64),\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1106'>1107</a>\u001b[0m     testing_target\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64),\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1107'>1108</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tpot/base.py?line=1108'>1109</a>\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:216\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=192'>193</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=193'>194</a>\u001b[0m     \u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=194'>195</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=195'>196</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=213'>214</a>\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=214'>215</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=215'>216</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_score(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=216'>217</a>\u001b[0m         partial(_cached_call, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=217'>218</a>\u001b[0m         estimator,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=218'>219</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=219'>220</a>\u001b[0m         y_true,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=220'>221</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=221'>222</a>\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:258\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=229'>230</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_score\u001b[39m(\u001b[39mself\u001b[39m, method_caller, estimator, X, y_true, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=230'>231</a>\u001b[0m     \u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=231'>232</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=232'>233</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=254'>255</a>\u001b[0m \u001b[39m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=255'>256</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=257'>258</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=258'>259</a>\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=259'>260</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=260'>261</a>\u001b[0m             y_true, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=261'>262</a>\u001b[0m         )\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:68\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=65'>66</a>\u001b[0m \u001b[39m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=67'>68</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(estimator, method)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=69'>70</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/sklearn/metrics/_scorer.py?line=70'>71</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[method]\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:113\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/metaestimators.py?line=109'>110</a>\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/metaestimators.py?line=111'>112</a>\u001b[0m     \u001b[39m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/metaestimators.py?line=112'>113</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(obj, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/metaestimators.py?line=113'>114</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/metaestimators.py?line=115'>116</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=466'>467</a>\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=467'>468</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=468'>469</a>\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=469'>470</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\pipeline.py:1222\u001b[0m, in \u001b[0;36mFeatureUnion.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1206'>1207</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1207'>1208</a>\u001b[0m     \u001b[39m\"\"\"Transform X separately by each transformer, concatenate results.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1208'>1209</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1209'>1210</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1219'>1220</a>\u001b[0m \u001b[39m        sum of `n_components` (output dimension) over transformers.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1220'>1221</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1221'>1222</a>\u001b[0m     Xs \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1222'>1223</a>\u001b[0m         delayed(_transform_one)(trans, X, \u001b[39mNone\u001b[39;49;00m, weight)\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1223'>1224</a>\u001b[0m         \u001b[39mfor\u001b[39;49;00m name, trans, weight \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iter()\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1224'>1225</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1225'>1226</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Xs:\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1226'>1227</a>\u001b[0m         \u001b[39m# All transformers are None\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=1227'>1228</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\pipeline.py:876\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=874'>875</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=875'>876</a>\u001b[0m     res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=876'>877</a>\u001b[0m     \u001b[39m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/pipeline.py?line=877'>878</a>\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tpot\\builtins\\stacking_estimator.py:87\u001b[0m, in \u001b[0;36mStackingEstimator.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tpot/builtins/stacking_estimator.py?line=84'>85</a>\u001b[0m \u001b[39m# add class probabilities as a synthetic feature\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tpot/builtins/stacking_estimator.py?line=85'>86</a>\u001b[0m \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator, \u001b[39m'\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> <a href='file:///c%3A/Python38/lib/site-packages/tpot/builtins/stacking_estimator.py?line=86'>87</a>\u001b[0m     y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tpot/builtins/stacking_estimator.py?line=87'>88</a>\u001b[0m     \u001b[39m# check all values that should be not infinity or not NAN\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tpot/builtins/stacking_estimator.py?line=88'>89</a>\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39misfinite(y_pred_proba)):\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1243\u001b[0m, in \u001b[0;36mMLPClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1228'>1229</a>\u001b[0m \u001b[39m\"\"\"Probability estimates.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1229'>1230</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1230'>1231</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1239'>1240</a>\u001b[0m \u001b[39m    model, where classes are ordered as they are in `self.classes_`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1240'>1241</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1241'>1242</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1242'>1243</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_pass_fast(X)\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1244'>1245</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=1245'>1246</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:159\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=142'>143</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_pass_fast\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=143'>144</a>\u001b[0m     \u001b[39m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=144'>145</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=145'>146</a>\u001b[0m \u001b[39m    This is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=156'>157</a>\u001b[0m \u001b[39m        The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=157'>158</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=158'>159</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=160'>161</a>\u001b[0m     \u001b[39m# Initialize first layer\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/neural_network/_multilayer_perceptron.py?line=161'>162</a>\u001b[0m     activation \u001b[39m=\u001b[39m X\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=584'>585</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=586'>587</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=396'>397</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=398'>399</a>\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=399'>400</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=400'>401</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=401'>402</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/sklearn/base.py?line=402'>403</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 23 features, but MLPClassifier is expecting 22 features as input."
     ]
    }
   ],
   "source": [
    "tpot_classifier.score(x_test, y_test) # 14days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_classifier.export('tpot_test.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = dp.scale_split(df_fil, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test= x_test.drop(['signals_0d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58203125"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = dp.scale_split(df_fil, 1, 1)\n",
    "x_test= x_test.drop(['signals_1d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6171875"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_classifier.score(x_test, y_test) # 1days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
